# Технологическая архитектура InsureTech (to-be)
Требования
 *	соответствие требованиям бизнеса по SLA и UX;
 *	масштабируемость при росте B2C- и B2B-нагрузки;
 *	отказоустойчивость и снижение финансовых потерь от простоев;
 *	готовность к запуску нового продукта — онлайн-оформления ОСАГО.


## Общая стратегия масштабирования и отказоустойчивости
В качестве базовой стратегии выбрано горизонтальное масштабирование сервисов в сочетании с размещением инфраструктуры в нескольких зонах доступности (multi-AZ).

Вертикальное масштабирование не рассматривается как основное решение, поскольку:
 *	не устраняет точки отказа (SPOF);
 *	плохо масштабируется при неравномерной и burst-нагрузке;
 *	не решает проблемы деградации при внешних интеграциях.

Горизонтальное масштабирование позволяет:
 *	независимо масштабировать сервисы;
 *	изолировать нагрузку от партнёров;
 *	повысить устойчивость к сбоям на уровне зоны доступности.


## Конфигурация Kubernetes
Используется один Managed Kubernetes Cluster, развёрнутый одновременно в двух зонах доступности.

Причины выбора одного multi-AZ кластера:
 *	упрощение эксплуатации и CI/CD;
 *	отсутствие необходимости в сложной синхронизации между кластерами;
 *	достаточный уровень отказоустойчивости для текущего масштаба бизнеса.

В каждой зоне доступности размещены worker-ноды, на которых запущены реплики всех stateless-сервисов.

Для повышения устойчивости применяются:
 *	PodAntiAffinity для pod’ов одного сервиса;
 *	PodDisruptionBudget;
 *	readiness / liveness probes.


## Балансировка нагрузки и входной трафик
### Внешний доступ
Входной трафик организован следующим образом:

Internet → Global Load Balancer → Ingress Controller → Kubernetes Services

Global Load Balancer
 *	распределяет трафик между зонами доступности;
 *	выполняет health check Ingress Controller (/health).

Ingress Controller
 *	выполняет TLS termination;
 *	маршрутизирует запросы к backend-сервисам;
 *	применяет rate limiting для B2B-клиентов (по API key);
 *	выполняет health check core-app (/ready).

Данный подход предотвращает ситуацию, при которой один партнёр исчерпывает ресурсы всей системы.

## Конфигурация базы данных
### Postgres
Используется кластер PostgreSQL, развернутый в двух зонах доступности:
 *	Primary — AZ-1;
 *	Replica — AZ-2.

Применяется streaming replication, что обеспечивает:
 *	RPO < 5 секунд;
 *	RTO — несколько минут при автоматическом failover.

Резервное копирование
 *	регулярные full-backup;
 *	поддержка point-in-time recovery;
 *	хранение резервных копий в Object Storage.

### Шардирование
На текущем этапе шардирование БД не применяется, так как:
 *	текущие объёмы данных и RPS этого не требуют;
 *	усложняется транзакционная модель.

## Итог
Предложенная архитектура:
 *	устраняет SPOF текущего решения;
 *	обеспечивает соблюдение SLA для B2B-клиентов;
 *	улучшает UX для B2C-пользователей;
 *	готова к росту нагрузки и запуску продукта ОСАГО;
 *	является эволюционным развитием текущей системы без избыточной сложности.
